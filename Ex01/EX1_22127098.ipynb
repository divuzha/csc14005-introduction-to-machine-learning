{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài tập 1\n",
    "\n",
    "\n",
    "Đinh Vũ Gia Hân - 22127098\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \n",
    "(i): The developers use exact coin specifications from the U.S. Mint to classify the coins.Because this process is based on predefined knowlegde rather than learning from a train set, so that the system isn't learning from data but simply creating models based on existing rules created by humans.\n",
    "\n",
    "(ii): In this case, the algorithm is provided a large set of labeled coins. It uses this data to infer decision boundaries, which is a typical of supervised learning. The algorithm learns from a train set and tries to map coin features (inputs) to coin denomination (outputs).\n",
    "\n",
    "(iii): The computer learns by playing repeatedly and adjusts its strategy based on penalties for bad moves. This is an example of reinforcement learning, where the system learns by rewarding correct moves and punshiing incorrect moves.\n",
    "\n",
    "So the correct answer is: [d] (i) Not learning, (ii) Supervised Learning, (iii) Reinforcement Learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n",
    "(i): This problem is more of a mathematical issue that has been cleared by humans. Since it can be solved with traditional algorithm methods (ex: using Miller algorithm), it is not suitable for machine learning. Machine learning is used to predict results from the training set, while determining prime numbers requires accurate calculations using available algorithms.\n",
    "\n",
    "(ii): This is a classic problem of machine learning. Fraud detection requires finding patterns in a transaction dataset (like location, amount, frequency and receiver) that humans might not easily notice. Since it used a large dataset to predict, it's well-suited for machine learning.\n",
    "\n",
    "(iii): This problem is more of a physics issue that can be solved with deterministic equations (ex: using Newton's laws of motion). Since determining the fallling time of an object is based on its weight and the solution is easily handled by mathematics, this problem is not well-suited for machine learning.\n",
    "\n",
    "(iv): This is a complex optimization problem involving many factors like traffic low, waiting time, amount of vehicles, and real-time adjustments. Machine learning models can be applied to learn and optimize traffic light cycles based on dynamic date, so it is suitable for machine learning.\n",
    "\n",
    "So the correct answer is: [a] (ii) and (iv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\n",
    "Define events:\n",
    "- $B_1$ is the event that we picked Bag 1 (contain 2 black balls)  \n",
    "- $B_2$ is the event that we picked Bag 2 (contain 1 black ball and 1 white ball)\n",
    "- $A_1$ is the event that the first ball we picked is black \n",
    "- $A_2$ is the event that the second ball we picked is black \n",
    "\n",
    "The first ball picked from the random bag is black. In order to the second ball picked from the same bag to be black, the probability of picking another black ball must be $P(A_2 | A_1)$\n",
    "\n",
    "By using Bayes' theorem, we have: $P(A_2 | A_1) = \\frac{P(A_2, A_1)}{P(A_1)}$ (1)\n",
    "\n",
    "In order for both balls to be black, we must choose Bag 1: $P(A_2, A_1) = \\frac{1}{2}$ (2)\n",
    "\n",
    "From the define event we have:\n",
    "- $P(B_1) = \\frac{1}{2}$\n",
    "- $P(B_2) = \\frac{1}{2}$\n",
    "- $P(A_1 | B_1) = 1$\n",
    "- $P(A_1 | B_2) = \\frac{1}{2}$\n",
    "\n",
    "So that: $P(A_1) = P(B_1) \\times P(A_1 | B_1) +  P(B_2) \\times P(A_1 | B_2) = 1 \\times \\frac{1}{2} +  \\frac{1}{2} \\times  \\frac{1}{2} =  \\frac{3}{4}$ (3)\n",
    "\n",
    "From (1), (2) and (3) we can infer: \n",
    "$P(A_2 | A_1) = \\frac{P(A_2, A_1)}{P(A_1)} = \\frac{\\frac{1}{2}}{\\frac{3}{4}} =  \\frac{2}{3}$\n",
    "\n",
    "So the correct answer is: [d] $ \\frac{2}{3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\n",
    "In a sample of 10 marbles, drawn with replacement, we have:\n",
    "- The probability that any marble drawn is red: $\\mu = 0.55$\n",
    "- The probability that any marble drawn is green: $1 - \\mu = 1 - 0.55 = 0.45$\n",
    "\n",
    "So the probability of getting no red marbles is $(0.45)^{10}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pickARed = 0.55\n",
    "p_pickAGreen = 1 - p_pickARed\n",
    "\n",
    "p_a = 7.331 * 10**-6\n",
    "p_b = 3.405 * 10**-4\n",
    "p_c = 0.289\n",
    "p_d = 0.450\n",
    "p_e = 0.550"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of getting no red marbles is 0.0003405062891601559\n"
     ]
    }
   ],
   "source": [
    "p_pickNoRed = p_pickAGreen ** 10\n",
    "print(\"The probability of getting no red marbles is\", p_pickNoRed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error of the answers\n",
      "[a] 0.0003331752891601559\n",
      "[b] 6.289160155929351e-09\n",
      "[c] 0.2886594937108398\n",
      "[d] 0.44965949371083985\n",
      "[e] 0.5496594937108399\n"
     ]
    }
   ],
   "source": [
    "print(\"The error of the answers\")\n",
    "print(\"[a]\", abs(p_a - p_pickNoRed))\n",
    "print(\"[b]\", abs(p_b - p_pickNoRed))\n",
    "print(\"[c]\", abs(p_c - p_pickNoRed))\n",
    "print(\"[d]\", abs(p_d - p_pickNoRed))\n",
    "print(\"[e]\", abs(p_e - p_pickNoRed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "So the correct answer is: [b] $3.405 \\times 10^{-4}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\n",
    "In 1000 independent samples, we have: \n",
    "- The probability that a single sample does not have $\\nu = 0$ is $1 - $3.405 \\times 10^{-4}$\n",
    "- The probability that none of 1000 samples does not have $\\nu = 0$ is $(1 - 3.405 \\times 10^{-4})^{1000}$\n",
    "\n",
    "So the probability that (at least) one of the samples has $\\nu = 0$ is  $1 - (1 - 3.405 \\times 10^{-4})^{1000}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of getting at least one red marble is 0.28863119784980995\n"
     ]
    }
   ],
   "source": [
    "p_ASampleHaveRed = 1 - p_pickNoRed \n",
    "p_1000SampleHaveRed = p_ASampleHaveRed ** 1000\n",
    "p_AtLeastOneRed = 1 - p_1000SampleHaveRed\n",
    "print(\"The probability of getting at least one red marble is\", p_AtLeastOneRed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error of the answers\n",
      "[a] 0.28862386684980995\n",
      "[b] 0.28829069784980993\n",
      "[c] 0.0003688021501900285\n",
      "[d] 0.16136880215019006\n",
      "[e] 0.2613688021501901\n"
     ]
    }
   ],
   "source": [
    "print(\"The error of the answers\")\n",
    "print(\"[a]\", abs(p_a - p_AtLeastOneRed))\n",
    "print(\"[b]\", abs(p_b - p_AtLeastOneRed))\n",
    "print(\"[c]\", abs(p_c - p_AtLeastOneRed))\n",
    "print(\"[d]\", abs(p_d - p_AtLeastOneRed))\n",
    "print(\"[e]\", abs(p_e - p_AtLeastOneRed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the correct answer is: [c] $0.289$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.\n",
    "This exercise is referenced from the source [1]. \n",
    "\n",
    "[a] g returns 1 for all three points.\n",
    "| $X_n$   | $y_n$ | g   | $f_1$ | $f_2$ | $f_3$ | $f_4$ | $f_5$ | $f_6$ | $f_7$ | $f_8$ |\n",
    "|---------|-------|-----|-------|-------|-------|-------|-------|-------|-------|-------|\n",
    "| 1 0 1   |       | 1   | 0     | 0     | 0     | 0     | 1     | 1     | 1     | 1     |\n",
    "| 1 1 0   |       | 1   | 0     | 0     | 1     | 1     | 0     | 0     | 1     | 1     |\n",
    "| 1 1 1   |       | 1   | 0     | 1     | 0     | 1     | 0     | 1     | 0     | 1     |\n",
    "\n",
    "The number of target functions agreeing with hypothesis on 3 points: 1 ($f_8$)<br>\n",
    "The number of target functions agreeing with hypothesis on 2 points: 3 ($f_4, f_6, f_7$)<br>\n",
    "The number of target functions agreeing with hypothesis on 1 point: 3 ($f_2, f_3, f_5$) <br>\n",
    "The number of target functions agreeing with hypothesis on 0 point: 1 ($f_1$)\n",
    "\n",
    "$\\rightarrow Score = 1 \\times 3 + 3 \\times 2 + 3 \\times 1 + 0 \\times 1 = 12$\n",
    "\n",
    "[b] g returns 0 for all three points.\n",
    "| $X_n$   | $y_n$ | g   | $f_1$ | $f_2$ | $f_3$ | $f_4$ | $f_5$ | $f_6$ | $f_7$ | $f_8$ |\n",
    "|---------|-------|-----|-------|-------|-------|-------|-------|-------|-------|-------|\n",
    "| 1 0 1   |       | 0   | 0     | 0     | 0     | 0     | 1     | 1     | 1     | 1     |\n",
    "| 1 1 0   |       | 0   | 0     | 0     | 1     | 1     | 0     | 0     | 1     | 1     |\n",
    "| 1 1 1   |       | 0   | 0     | 1     | 0     | 1     | 0     | 1     | 0     | 1     |\n",
    "\n",
    "The number of target functions agreeing with hypothesis on 3 points: 1 ($f_1$)<br>\n",
    "The number of target functions agreeing with hypothesis on 2 points: 3 ($f_2, f_3, f_5$)<br>\n",
    "The number of target functions agreeing with hypothesis on 1 point: 3 ($f_4, f_6, f_7$) <br>\n",
    "The number of target functions agreeing with hypothesis on 0 point: 1 ($f_8$)\n",
    "\n",
    "$\\rightarrow Score = 1 \\times 3 + 3 \\times 2 + 3 \\times 1 + 0 \\times 1 = 12$\n",
    "\n",
    "[c] g is the XOR function applied to x, i.e., if the number of 1s in x is odd, g returns 1; if it is even, g returns 0.\n",
    "\n",
    "We have:\n",
    "- (1 0 1) has two numbers 1 $\\rightarrow$ g return 0\n",
    "- (1 1 0) has two numbers 1 $\\rightarrow$ g return 0\n",
    "- (1 1 1) has three numbers 1 $\\rightarrow$ g return 1\n",
    "\n",
    "| $X_n$   | $y_n$ | g   | $f_1$ | $f_2$ | $f_3$ | $f_4$ | $f_5$ | $f_6$ | $f_7$ | $f_8$ |\n",
    "|---------|-------|-----|-------|-------|-------|-------|-------|-------|-------|-------|\n",
    "| 1 0 1   |       | 0   | 0     | 0     | 0     | 0     | 1     | 1     | 1     | 1     |\n",
    "| 1 1 0   |       | 0   | 0     | 0     | 1     | 1     | 0     | 0     | 1     | 1     |\n",
    "| 1 1 1   |       | 1   | 0     | 1     | 0     | 1     | 0     | 1     | 0     | 1     |\n",
    "\n",
    "The number of target functions agreeing with hypothesis on 3 points: 1 ($f_2$)<br>\n",
    "The number of target functions agreeing with hypothesis on 2 points: 3 ($f_1, f_4, f_6$)<br>\n",
    "The number of target functions agreeing with hypothesis on 1 point: 3 ($f_3, f_5, f_8$) <br>\n",
    "The number of target functions agreeing with hypothesis on 0 point: 1 ($f_7$)\n",
    "\n",
    "$\\rightarrow Score = 1 \\times 3 + 3 \\times 2 + 3 \\times 1 + 0 \\times 1 = 12$\n",
    "\n",
    "[d] g returns the opposite of the XOR function: if the number of 1s is odd, it returns 0, otherwise returns 1.\n",
    "\n",
    "We have:\n",
    "- (1 0 1) has two numbers 1 $\\rightarrow$ g return 1\n",
    "- (1 1 0) has two numbers 1 $\\rightarrow$ g return 1\n",
    "- (1 1 1) has three numbers 1 $\\rightarrow$ g return 0\n",
    "\n",
    "| $X_n$   | $y_n$ | g   | $f_1$ | $f_2$ | $f_3$ | $f_4$ | $f_5$ | $f_6$ | $f_7$ | $f_8$ |\n",
    "|---------|-------|-----|-------|-------|-------|-------|-------|-------|-------|-------|\n",
    "| 1 0 1   |       | 1   | 0     | 0     | 0     | 0     | 1     | 1     | 1     | 1     |\n",
    "| 1 1 0   |       | 1   | 0     | 0     | 1     | 1     | 0     | 0     | 1     | 1     |\n",
    "| 1 1 1   |       | 0   | 0     | 1     | 0     | 1     | 0     | 1     | 0     | 1     |\n",
    "\n",
    "The number of target functions agreeing with hypothesis on 3 points: 1 ($f_7$)<br>\n",
    "The number of target functions agreeing with hypothesis on 2 points: 3 ($f_3, f_5, f_8$)<br>\n",
    "The number of target functions agreeing with hypothesis on 1 point: 3 ($f_1, f_4, f_6$) <br>\n",
    "The number of target functions agreeing with hypothesis on 0 point: 1 ($f_2$)\n",
    "\n",
    "$\\rightarrow Score = 1 \\times 3 + 3 \\times 2 + 3 \\times 1 + 0 \\times 1 = 12$\n",
    "\n",
    "So the correct answer is: [e] They are all equivalent (equal scores for g in [a] through [d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7-10. \n",
    "\n",
    "This exercise is referenced from the source [2]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Định nghĩa các hàm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm phát sinh ra `target_w`, véc-tơ tham số của $f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_target_w():\n",
    "    \"\"\"\n",
    "    Generates target_w from two random, uniformly distributed points in [-1, 1] x [-1, 1].\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    target_w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    \"\"\"\n",
    "    # Generate two points from a uniform distribution over [-1, 1]x[-1, 1]\n",
    "    p1 = np.random.uniform(-1, 1, 2)\n",
    "    p2 = np.random.uniform(-1, 1, 2)\n",
    "    # Compute the target W from these two points\n",
    "    target_w = np.array([p1[1] * p2[0] - p1[0] * p2[1], p2[1] - p1[1], p1[0] - p2[0]]).reshape((-1, 1))\n",
    "    \n",
    "    return target_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm phát sinh ra tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(N, target_w):\n",
    "    \"\"\"\n",
    "    Generates a data set by generating random inputs and then using target_w to generate the \n",
    "    corresponding outputs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of examples.\n",
    "    target_w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of f.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    Y : numpy array, shape (N, 1)\n",
    "        The vector of outputs.        \n",
    "    \"\"\"\n",
    "    X = np.random.uniform(-1, 1, (N, 2))\n",
    "    X = np.hstack((np.ones((N, 1)), X)) # Add 'ones' column\n",
    "    Y = np.sign(np.dot(X, target_w))\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm chạy PLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_PLA(X, Y):\n",
    "    \"\"\"\n",
    "    Runs PLA.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : numpy array, shape (N, 3)\n",
    "        The matrix of input vectors (each row corresponds to an input vector); the first column of \n",
    "        this matrix is all ones.\n",
    "    Y : numpy array, shape (N, 1)\n",
    "        The vector of outputs.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    w : numpy array, shape (3, 1) \n",
    "        The vector of parameters of g.\n",
    "    num_iterations : int\n",
    "        The number of iterations PLA takes to converge.\n",
    "    \"\"\"\n",
    "    w = np.zeros((X.shape[1], 1)) # Init w\n",
    "    iteration = 0\n",
    "    \n",
    "    # TODO\n",
    "    while True:\n",
    "        misclassified = [] # List of misclassified points\n",
    "        for i in range(X.shape[0]):\n",
    "            # Check if the point is misclassified\n",
    "            if np.sign(np.dot(X[i], w)) != Y[i]:\n",
    "                misclassified.append(i)\n",
    "                w += Y[i] * X[i].reshape(-1, 1) # Update w\n",
    "                iteration += 1\n",
    "\n",
    "        # If no point is misclassified, stop the loop\n",
    "        if len(misclassified) == 0:\n",
    "            break\n",
    "    \n",
    "    return w, iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(N):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    N : int\n",
    "        The number of training examples.\n",
    "    \"\"\"\n",
    "    num_runs = 1000\n",
    "    avg_num_iterations = 0.0 # The average number of iterations PLA takes to converge\n",
    "    avg_test_err = 0.0 # The average test error of g - the final hypothesis picked by PLA\n",
    "    \n",
    "    for r in range(num_runs):\n",
    "        # Generate target_w\n",
    "        target_w = generate_target_w()\n",
    "        \n",
    "        # Generate training set\n",
    "        X, Y = generate_data(N, target_w)\n",
    "        \n",
    "        # Run PLA to pick g\n",
    "        w, num_iterations = run_PLA(X, Y)\n",
    "        \n",
    "        # Generate test set\n",
    "        X_test, Y_test = generate_data(10000, target_w)\n",
    "        \n",
    "        # Test g\n",
    "        test_err = np.mean(np.sign(np.dot(X_test, w)) != Y_test)\n",
    "        \n",
    "        # Update average values\n",
    "        avg_num_iterations += (num_iterations * 1.0 / num_runs)\n",
    "        avg_test_err += (test_err * 1.0 / num_runs)\n",
    "    \n",
    "    # Print results\n",
    "    print('avg_num_iterations = %f' % (avg_num_iterations))\n",
    "    print('avg_test_err = %f' % (avg_test_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chạy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_num_iterations = 9.843000\n",
      "avg_test_err = 0.111970\n"
     ]
    }
   ],
   "source": [
    "main(N=10) # We can use `main(10)`, but `main(N=10)` is clearer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Câu 7: ta thấy kết quả gần nhất với đáp án [b] 15.\n",
    "\n",
    "Câu 8: ta thấy kết quả gần nhất với đáp án [c] 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_num_iterations = 133.822000\n",
      "avg_test_err = 0.013709\n"
     ]
    }
   ],
   "source": [
    "main(N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Câu 9: ta thấy kết quả gần nhất với đáp án [b] 100\n",
    "\n",
    "Câu 10: ta thấy kết quả gần nhất với đáp án [b] 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1]: Hotaj, Eugen. \"Why Is Machine Learning Feasible?\" <i>Medium</i>, 30 November 2019, https://towardsdatascience.com/is-learning-feasible-8e9c18b08a3c. (Accessed date: 19/10/2024)\n",
    "\n",
    "[2]: \"Bài 9: Perceptron Learning Algorithm\" <i>Machine Learning cơ bản</i>, 21 January 2017, https://machinelearningcoban.com/2017/01/21/perceptron/. (Accessed date: 19/10/2024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
